{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URq7GjaJch6g"
   },
   "source": [
    "# Neural Networks\n",
    "\n",
    "In this activity we are going to build a simple neural network (NN) to detect numbers in images. Our NN will be created using `tensorflow/keras` package from Python. We will also use `matplotlib` for showing some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2ou6XUgdwxe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb-xJJ31dRJF"
   },
   "source": [
    "\n",
    "## Dataset\n",
    "\n",
    "In this example, we are going to use the MNIST classical dataset. This  dataset is already present in Tensorflow module which can be accessed using the API `tf.keras.dataset.mnist`.\n",
    "\n",
    "MNIST dataset consists of 60,000 training images and 10,000 test images along with labels representing the digit present in the image. Each image is represented by 28×28 grayscale pixels.\n",
    "\n",
    "In the next code, the dataset is loaded and see the shape of datasets and also the how our dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 713
    },
    "id": "PMjs2K0qe7K1",
    "outputId": "47ab171f-02cf-42ac-e8da-9590b2d6857c"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels) , (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Printing the shapes\n",
    "print(\"train_images shape: \", train_images.shape)\n",
    "print(\"train_labels shape: \", train_labels.shape)\n",
    "print(\"test_images shape: \", test_images.shape)\n",
    "print(\"test_labels shape: \", test_labels.shape)\n",
    " \n",
    " \n",
    "# Displaying first 9 images of dataset\n",
    "fig = plt.figure(figsize=(10,10))\n",
    " \n",
    "nrows=3\n",
    "ncols=3\n",
    "for i in range(9):\n",
    "  fig.add_subplot(nrows, ncols, i+1)\n",
    "  plt.imshow(train_images[i])\n",
    "  plt.title(\"Digit: {}\".format(train_labels[i]))\n",
    "  plt.axis(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xzwo7qqPhm0V"
   },
   "source": [
    "## Preparing the data\n",
    "\n",
    "You should always preprocess your data before moving it to train a neural network. Preprocessing the dataset makes it ready as input to the machine learning model.\n",
    "\n",
    "Images in our dataset are made up of grayscale pixels in range 0 – 255. Machine Learning models works better if the range of values dataset is using is small. So we convert its range to 0 – 1 by dividing it by 255.\n",
    "\n",
    "We also convert our labels from digit labels to one-hot encoded vectors. One-hot encoded vector is a binary vector representation of labels in which all elements are 0 except index of the corresponding label whose value is 1. We will use to_categorical() method to convert labels to one-hot.\n",
    "\n",
    "For example, for label 2, index 2 will have have 1, rest all will be 0. ( [ 0 0 1 0 0 0 0 0 0 0 ] )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVk1NIDshxOc",
    "outputId": "61c37d75-daea-4057-81fb-863bfba10d17"
   },
   "outputs": [],
   "source": [
    "# Converting image pixel values to 0 - 1\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255\n",
    " \n",
    "print(\"First Label before conversion:\")\n",
    "print(train_labels[0])\n",
    " \n",
    "# Converting labels to one-hot encoded vectors\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    " \n",
    "print(\"First Label after conversion:\")\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-E90Lr2h_Ay"
   },
   "source": [
    "## Building the Neural Network\n",
    "\n",
    "Building a neural network takes 2 steps: configuring the layers and compiling the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkcU9Gq8iGyk"
   },
   "source": [
    "### Setup the layers\n",
    "\n",
    "This will be the architecture of our model will be composed of three layers (the input layer, a hidden layer and the output layer):\n",
    "\n",
    "1. **Input layer (flatten layer)**: Our input images are 2D arrays. Flatten layer converts the 2D arrays(of 28 by 28 pixels) into a 1D array(of 28*28=784 pixels) by unstacking the rows one after another. This layer just changes the data shape and no parameters/weights are learned. Code: ` tf.keras.layers.Flatten()`\n",
    "2. **Hidden Layer**: Our only hidden layer consists of a fully connected (Dense layer) of 512 neurons each with relu activation function. Code: `tf.keras.layers.Dense(units=512, activation='relu')`\n",
    "3. **Output Layer**: The output layer of the neural network consists of a Dense layer with 10 output neurons which outputs 10 probabilities each for digit 0 – 9 representing the probability of the image being the corresponding digit. The output layer is given softmax activation function to convert input activations to probabilities. Code: `tf.keras.layers.Dense(units=10, activation='softmax')`\n",
    "\n",
    "Since the output of each layer is input to a single layer only and all the layers are stacked in linear fashion, we will use Sequential() API that takes a list of layers that will come in order one after another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "S1ez5_hdjmgt"
   },
   "outputs": [],
   "source": [
    "# Using Sequential() to build layers one after another\n",
    "model = tf.keras.Sequential([\n",
    "  # Flatten Layer that converts images to 1D array\n",
    "  tf.keras.layers.Flatten(),\n",
    "  # Hidden Layer with 512 units and relu activation\n",
    "  tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "  # Output Layer with 10 units for 10 classes and softmax activation\n",
    "  tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQiThbeFlBnD"
   },
   "source": [
    "### Compiling the model\n",
    "\n",
    "Before we train our model, we need to tell our model a few things. Here are the 3 attributes given to the model during the models compile step:\n",
    "\n",
    "1. **Loss Function:** This tells our model how to find the error between the actual label and the label predicted by the model.  The choice for a loss function depends on the task that you have at hand: for example, for a regression problem, you’ll usually use the Mean Squared Error (MSE), or for binary classification problem, you'll use the `binary_crossentropy` for the binary classification problem. As you see, we make use of `categorical_crossentropy` since our problem is a multi-class classification.\n",
    "2. **Optimizer**: This tells our model how to update weights/parameters of the model by looking at the data and loss function value. We will use `adam` optimizer for our model. Some other popular optimization algorithms used are the Stochastic Gradient Descent (SGD) and RMSprop.\n",
    "3. **Metrics(Optional):** It contains a list of metrics used to monitor the train and test steps. We will use accuracy or the number of images our model classifies correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VyIm29DmmWDW"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss = 'categorical_crossentropy',\n",
    "  optimizer = 'adam',\n",
    "  metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_idlvINrmjnE"
   },
   "source": [
    "### Training the model\n",
    "\n",
    "To train our neural network, we will call `fit()` method on model that takes:\n",
    "1. **Training Data:** In this, we will use `train_images` consisting of images that we will feed to the neural network.\n",
    "2. **Training Labels:** In this, we will use `train_labels` consisting of labels that represent the output of our training images.\n",
    "3. **Epochs:** Epochs are the number of times our model will iterate on all training examples. For example, if we specify 10 epochs, then our model will run on all 60,000 training images 10 times.\n",
    "\n",
    "`fit()` method returns a history object that contains the loss values and metrics specified during compile time after each epoch.\n",
    "\n",
    "In the next code, our model is trained and some figures about the accuracy/loss is showm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "id": "PkOyL82dnTX7",
    "outputId": "026bfb98-2dfa-43ff-9e1b-a870309ea37f"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  x = train_images,\n",
    "  y = train_labels,\n",
    "  epochs = 10\n",
    ")\n",
    "\n",
    "# Showing plot for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['loss'])\n",
    "plt.show()\n",
    " \n",
    "# Showing plot for accuracy\n",
    "plt.plot(history.history['accuracy'], color='orange')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwJEJD8n2F8"
   },
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Now we have trained our neural network, we would like to see how it performs on data our model haven’t seen before. For this we will use our test dataset to see how much accurate it is. For this we will call `evaluate()` method on model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqyWDM1OoSyu",
    "outputId": "8a9202fa-39e9-43c5-9a20-8138ad1b1219"
   },
   "outputs": [],
   "source": [
    "# Call evaluate to find the accuracy on test images\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "  x = test_images, \n",
    "  y = test_labels\n",
    ")\n",
    " \n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i36wnn5Uona-"
   },
   "source": [
    "### Making predictions\n",
    "\n",
    "With our trained model, we can also make predictions on new images and see what our model identifies in the image. We make predictions in 2 steps:\n",
    "\n",
    "1. **Predicting Probabilities:** We will use `predict()` that will return the probabilities for an image of being it to one of the classes. In our example, for a single image, it will return 10 probabilities for each image representing probabilities of it being a digit 0 – 9.\n",
    "2. **Predicting Classes:** Now we have 10 probabilities, the class with maximum probability is the one predicted by the model. To find this, we will use `tf.argmax()` that will return the index with maximum value.\n",
    "\n",
    "Now you can see what our model has predicted. You can change the index to see output for different test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "t-lBWiWopJgD",
    "outputId": "0dfe622b-a253-488c-efc7-ed7ce18a0ebd"
   },
   "outputs": [],
   "source": [
    "predicted_probabilities = model.predict(test_images)\n",
    "predicted_classes = tf.argmax(predicted_probabilities, axis=-1).numpy()\n",
    "\n",
    "index=20\n",
    " \n",
    "# Showing image\n",
    "plt.imshow(test_images[index])\n",
    " \n",
    "# Printing Probabilities\n",
    "print(\"Probabilities predicted for image at index\", index)\n",
    "print(predicted_probabilities[index])\n",
    " \n",
    "print()\n",
    " \n",
    "# Printing Predicted Class\n",
    "print(\"Probabilities class for image at index\", index)\n",
    "print(predicted_classes[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl58kVQepbP9"
   },
   "source": [
    "## Experiment and Modify!\n",
    "\n",
    "In the next cell, you can see the code that we will use in the exercise. It is the same that in the previous sections, but all the images and most of the print are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1s9t9OGVpzzr",
    "outputId": "f5df98c3-7f26-495c-dc92-18e790311f38"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset \n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels) , (test_images, test_labels) = mnist.load_data()\n",
    " \n",
    "# Preparing data\n",
    "\n",
    "# Converting image pixel values to 0 - 1\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255\n",
    " \n",
    "# Converting labels to one-hot encoded vectors\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    " \n",
    " \n",
    "# Defining Model\n",
    "# Using Sequential() to build layers one after another\n",
    "model = tf.keras.Sequential([\n",
    "  # Flatten Layer that converts images to 1D array\n",
    "  tf.keras.layers.Flatten(),\n",
    "  # Hidden Layer with 512 units and relu activation\n",
    "  tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "  # Output Layer with 10 units for 10 classes and softmax activation\n",
    "  tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss = 'categorical_crossentropy',\n",
    "  optimizer = 'adam',\n",
    "  metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Training:\")\n",
    "history = model.fit(\n",
    "  x = train_images,\n",
    "  y = train_labels,\n",
    "  epochs = 10\n",
    ")\n",
    " \n",
    "print(\"\\nEvaluating:\")\n",
    "# Call evaluate to find the accuracy on test images\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "  x = test_images, \n",
    "  y = test_labels\n",
    ")\n",
    "\n",
    "print(\"\\n Results: \") \n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRnVczL9uNy8"
   },
   "source": [
    "You’ve successfully built your first model, but you can go even further with this one. Why not try out the following things and see what their effect is? \n",
    "\n",
    "Generate other models and test their accuracy. Great starting points to generate a new model are:\n",
    "\n",
    "* You used 1 hidden layers. Try to use more hidden layers.\n",
    "* Use hidden layers with more neurons or less neurons.\n",
    "* Instead of `relu` activation function, try using the `tanh` one (or `sigmoid` or `linear` ...)\n",
    "* Test other optimizers like `'sgd'` or `'rmsprop'`.\n",
    "* Try to adapt the [learning rate](https://en.wikipedia.org/wiki/Learning_rate) of the selected optimizer. To do this, instead of:\n",
    "```python\n",
    "model.compile(\n",
    "  loss = 'categorical_crossentropy',\n",
    "  optimizer = 'adam',\n",
    "  metrics = ['accuracy']\n",
    ")\n",
    "```\n",
    "use (`Adam` for `'adam'`, `SGD` for `'sgd'`, and `'RMSprop'` for `'rmsprop'`);\n",
    "```python\n",
    "model.compile(\n",
    "  loss = 'categorical_crossentropy',\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  metrics = ['accuracy']\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sO2uT9HRyqO4"
   },
   "outputs": [],
   "source": [
    "# For each model X, you have to:\n",
    "# 1.- Create the model -> modelX = tf.keras.Sequential([ ...\n",
    "# 2.- Compile the model -> modelX.compile(...\n",
    "# 3.- Train the model -> modelX.fit(...\n",
    "# 4.- Evaluate the model -> modelX.evaluate(...\n",
    "# 5.- Print the results -> print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBISrso6zSTP"
   },
   "source": [
    "Answer: (For each new model, describe how this model is different to the original. Fulfil the table with the accuracy)\n",
    "\n",
    "* New model 1:\n",
    "* ...\n",
    "\n",
    "Results (test accuracy):\n",
    "\n",
    "| Model | Test accuracy |\n",
    "| --- | --- |\n",
    "| Original | 0.9814 |\n",
    "| New model 1 | |\n",
    "| ... | |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ICD_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
